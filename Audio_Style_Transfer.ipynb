{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lnf5gwlzAc4_"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import torch.optim as optim\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np \n",
        "import torchvision.transforms as transforms\n",
        "import copy\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import librosa.display\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l8qaifiRAXLu"
      },
      "outputs": [],
      "source": [
        "#클래스 선언\n",
        "class CNNModel(nn.Module):\n",
        "\tdef __init__(self):\n",
        "\t\tsuper(CNNModel, self).__init__()\n",
        "\t\tself.cnn1 = nn.Sequential(\n",
        "\t\t\t\tnn.Conv2d(in_channels=1, out_channels=8, kernel_size=3, stride=1, padding=1),\n",
        "\t\t\t \tnn.ReLU())\n",
        "\t\tself.cnn2 = nn.Sequential(\n",
        "\t\t\t\tnn.Conv2d(in_channels=8, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
        "\t\t\t \tnn.ReLU()\n",
        "\t\t)\n",
        "\tdef forward(self, x):\n",
        "\t\tout = self.cnn1(x)\n",
        "\t\treturn out\n",
        "\"\"\"\n",
        "\tW * H * C ( 3 dim )\n",
        "\t->\n",
        "\t( W * H ) * C ( 2 dim )\n",
        "\"\"\"\n",
        "class GramMatrix(nn.Module):\n",
        "\tdef forward(self, input):\n",
        "\t\ta, b, c = input.size()\n",
        "\t\tfeatures = input.view(a * b, c) \n",
        "\t\tG = torch.mm(features, features.t())\n",
        "\t\treturn G.div(a * b * c)\n",
        "#좀 변경됨\n",
        "class StyleLoss(nn.Module):\n",
        "\tdef __init__(self, target, weight):\n",
        "\t\tsuper(StyleLoss, self).__init__()\n",
        "\t\tself.target = target.detach() * weight\n",
        "\t\tself.weight = weight\n",
        "\t\tself.gram = GramMatrix()\n",
        "\t\tself.criterion = nn.MSELoss()\n",
        "\n",
        "\tdef forward(self, input):\n",
        "\t\tself.output = input.clone()\n",
        "\t\tself.G = self.gram(input)\n",
        "\t\tself.G.mul_(self.weight)\n",
        "\t\tself.loss = self.criterion(self.G, self.target)\n",
        "\t\treturn self.output\n",
        "\n",
        "\tdef backward(self,retain_graph=True):\n",
        "\t\tself.loss.backward(retain_graph=retain_graph)\n",
        "\t\treturn self.loss\n",
        "\n",
        "class ContentLoss(nn.Module):\n",
        "\tdef __init__(self, target):\n",
        "\t\t\tsuper(ContentLoss, self).__init__()\n",
        "\t\t\tself.target = target.detach()\n",
        "\n",
        "\tdef forward(self, input):\n",
        "\t\t\tself.loss = nn.MSELoss(input, self.target)\n",
        "\t\t\treturn self.loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySvksZoNjRJd"
      },
      "source": [
        "# function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "75FLmvnVMWBE"
      },
      "outputs": [],
      "source": [
        "#variable\n",
        "N_FFT=2048\n",
        "style_weight=1025\n",
        "content_weight = 1025\n",
        "style_layers_default = ['conv_1']\n",
        "content_layers_default = ['conv_1']\n",
        "learning_rate_initial = 0.03\n",
        "num_steps= 2500"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5apC4h70G-VA"
      },
      "outputs": [],
      "source": [
        "import torchaudio.transforms as T\n",
        "\n",
        "def read_audio_spectum(filename, off):\n",
        "\tx, fs = librosa.load(filename, duration=47.54, offset = off)\n",
        "\tS = librosa.stft(x, N_FFT)\n",
        "\tp = np.angle(S)\n",
        "\tS = np.log1p(np.abs(S))  \n",
        "\treturn S, fs\n",
        "\n",
        "def get_style_model_and_losses(cnn, style_float,content_float,style_weight=style_weight,content_weight = content_weight, style_layers=style_layers_default, content_layers = content_layers_default): \n",
        "\tcnn = copy.deepcopy(cnn)\n",
        "\tstyle_losses = []\n",
        "\tcontent_losses = []\n",
        "\n",
        "\tmodel = nn.Sequential()  \n",
        "\tgram = GramMatrix() \n",
        "\tif torch.cuda.is_available():\n",
        "\t\tmodel = model.cuda()\n",
        "\t\tgram = gram.cuda()\n",
        "\t\n",
        "\t# i = 0  # increment every time we see a conv\n",
        "\t# for layer in cnn.children():\n",
        "\t\t\n",
        "\t# \ti += 1\n",
        "\t# \tname = 'conv_{}'.format(i)\n",
        "\t# \tprint(i)\n",
        "\t# \tprint(\"content_float :\",content_float.shape)\n",
        "\t# \tprint(\"style_float : \", style_float.shape)\n",
        "\t# \tif name in content_layers:\n",
        "\t# \t\ttarget_feature = model(content_float).clone()\n",
        "\t# \t\tcontent_loss = ContentLoss(target_feature)\n",
        "\t# \t\tmodel.add_module(\"content_loss_{}\".format(i), content_loss)\n",
        "\t# \t\tcontent_losses.append(content_loss)\n",
        "\t# \tif name in style_layers:\n",
        "\t# \t\ttarget_feature = model(style_float).clone()\n",
        "\t# \t\ttarget_feature_gram = gram(target_feature)\n",
        "\t# \t\tstyle_loss = StyleLoss(target_feature_gram, style_weight)\n",
        "\t# \t\tmodel.add_module(\"style_loss_{}\".format(i), style_loss)\n",
        "\t# \t\tstyle_losses.append(style_loss)\t\t\n",
        "\t# \tmodel = model[:(i + 1)]\n",
        "\n",
        "\t\t# return model, style_losses, content_losses\n",
        "\tname = \"conv_1\"\n",
        "\tmodel.add_module(name, cnn.cnn1)\n",
        " \n",
        "\tif name in style_layers:\n",
        "\t\ttarget_feature = model(style_float).clone()\n",
        "\t\ttarget_feature_gram = gram(target_feature)\n",
        "\t\tstyle_loss = StyleLoss(target_feature_gram, style_weight)\n",
        "\t\tmodel.add_module(\"style_loss_1\", style_loss)\n",
        "\t\tstyle_losses.append(style_loss)\n",
        "\t\t\n",
        "\treturn model, style_losses\n",
        "\n",
        "\n",
        "def get_input_param_optimizer(input_float):\n",
        "\tinput_param = nn.Parameter(input_float.data)\n",
        "\toptimizer = optim.Adam([input_param], lr=learning_rate_initial, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)\n",
        "\treturn input_param, optimizer, input_float\n",
        "\n",
        "def run_style_transfer(cnn, style_float, input_float, num_steps=num_steps, style_weight=style_weight, content_weight = content_weight): #STYLE WEIGHT, NUM_STEPS\n",
        "\tprint('Building the style transfer model..')\n",
        "\tmodel, style_losses= get_style_model_and_losses(cnn, style_float,input_float, style_weight, content_weight)\n",
        "\t# model, style_losses, content_losses= get_style_model_and_losses(cnn, style_float,input_float,style_weight, content_weight)\n",
        "\tinput_param, optimizer ,return_float= get_input_param_optimizer(input_float)\n",
        "\tprint('Optimizing..')\n",
        " #====================================\n",
        "\trun = [0]\n",
        "\tplt.figure(figsize = (15,5))\n",
        "\tinput_float.requires_grad_(False)\n",
        "\twhile run[0] <= num_steps:\n",
        "\t\tdef closure():\n",
        "\t\t\tinput_param.data.clamp_(0, 1)\n",
        "\t\t\toptimizer.zero_grad()\n",
        "\t\t\tmodel(input_param)\n",
        "\t\t\tstyle_score = 0\n",
        "\t\t\tcontent_score = 0\n",
        "\n",
        "\t\t\tfor sl in style_losses:\n",
        "\t\t\t\tstyle_score += sl.backward()\n",
        "\t\t\n",
        "\t\t\tcontent_loss = F.mse_loss(input_param, input_float)\n",
        "\t\t\tcontent_loss.backward()\n",
        "\t\t\t# for cs in content_losses:\n",
        "\t\t\t\t# content_score += cs();\n",
        "\n",
        "\t\t\trun[0] += 1\n",
        "\t\t\tif run[0] % 100 == 0:\n",
        "\t\t\t\tprint(\"run {}:\".format(run))\n",
        "\t\t\t\tprint('Style Loss : {:8f}'.format(style_score.data)) #CHANGE 4->8 \n",
        "\t\t\t\t# print('Content Loss : {:.8f}'.format(content_score))\n",
        "\t\t\t\tprint()\n",
        "\t\t\tif run[0] <100 and run[0] % 20 == 0:\n",
        "\t\t\t\tinput_np = input_param.data.detach().cpu().numpy()\n",
        "\t\t\t\tinput_np = np.squeeze(input_np, axis = 0)\n",
        "\t\t\t\tplt.subplot(1,5,run[0] / 20 + 1)\n",
        "\t\t\t\tplt.imshow(input_np)\n",
        "\t\t\t\tlibrosa.display.waveplot(input_np)\n",
        "\t\t\t\t\n",
        "\n",
        "\t\t\treturn style_score\n",
        "\t\toptimizer.step(closure)\n",
        "\t \n",
        "\tinput_param.data.clamp_(0, 1)\n",
        "\treturn input_param.data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32xYc_4yjVWD"
      },
      "source": [
        "#main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "a2j_9qnFxAzR",
        "outputId": "5c6682a4-b056-42a7-fe9f-c8754644ac83"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sampling Rates are same\n",
            "Building the style transfer model..\n",
            "Optimizing..\n",
            "run [100]:\n",
            "Style Loss : 0.000001\n",
            "\n",
            "run [200]:\n",
            "Style Loss : 0.000001\n",
            "\n",
            "run [300]:\n",
            "Style Loss : 0.000001\n",
            "\n",
            "run [400]:\n",
            "Style Loss : 0.000001\n",
            "\n",
            "run [500]:\n",
            "Style Loss : 0.000001\n",
            "\n",
            "run [600]:\n",
            "Style Loss : 0.000001\n",
            "\n",
            "run [700]:\n",
            "Style Loss : 0.000001\n",
            "\n",
            "run [800]:\n",
            "Style Loss : 0.000001\n",
            "\n",
            "run [900]:\n",
            "Style Loss : 0.000001\n",
            "\n",
            "run [1000]:\n",
            "Style Loss : 0.000001\n",
            "\n",
            "run [1100]:\n",
            "Style Loss : 0.000001\n",
            "\n",
            "run [1200]:\n",
            "Style Loss : 0.000001\n",
            "\n",
            "run [1300]:\n",
            "Style Loss : 0.000001\n",
            "\n",
            "run [1400]:\n",
            "Style Loss : 0.000001\n",
            "\n",
            "run [1500]:\n",
            "Style Loss : 0.000001\n",
            "\n",
            "run [1600]:\n",
            "Style Loss : 0.000001\n",
            "\n",
            "run [1700]:\n",
            "Style Loss : 0.000001\n",
            "\n",
            "run [1800]:\n",
            "Style Loss : 0.000001\n",
            "\n",
            "run [1900]:\n",
            "Style Loss : 0.000001\n",
            "\n",
            "run [2000]:\n",
            "Style Loss : 0.000001\n",
            "\n",
            "run [2100]:\n",
            "Style Loss : 0.000001\n",
            "\n",
            "run [2200]:\n",
            "Style Loss : 0.000001\n",
            "\n",
            "run [2300]:\n",
            "Style Loss : 0.000001\n",
            "\n",
            "run [2400]:\n",
            "Style Loss : 0.000001\n",
            "\n",
            "run [2500]:\n",
            "Style Loss : 0.000001\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [02:45<00:00,  3.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DONE...\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 4 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "\tstyle_audio, style_sr = read_audio_spectum('./la_campanella_violin.mp3',15)\n",
        "\tcontent_audio, content_sr = read_audio_spectum('./la_campanella_piano.mp3',16)\n",
        "\tif(content_sr == style_sr):\n",
        "\t\tprint('Sampling Rates are same')\n",
        "\telse:\n",
        "\t\tprint('Sampling rates are not same')\n",
        "\t\texit()\n",
        "\tstyle_audio = style_audio.reshape([1,1025,-1])\n",
        "\tcontent_audio = content_audio.reshape([1,1025,-1])\n",
        "\n",
        "\n",
        "\tif torch.cuda.is_available():\n",
        "\t\tstyle_float = Variable((torch.from_numpy(style_audio)).cuda())\n",
        "\t\tcontent_float = Variable((torch.from_numpy(content_audio)).cuda())\t\n",
        "\telse:\n",
        "\t\tstyle_float = Variable(torch.from_numpy(style_audio))\n",
        "\t\tcontent_float = Variable(torch.from_numpy(content_audio))\n",
        "\tinput_float = content_float.clone()\n",
        "\t\n",
        "\tcnn = CNNModel()\n",
        "\tif torch.cuda.is_available():\n",
        "\t\tcnn = cnn.cuda()\n",
        "\n",
        "\toutput = run_style_transfer(cnn, style_float, input_float)\n",
        "\tif torch.cuda.is_available():\n",
        "\t\toutput = output.cpu()\n",
        "\toutput = output.squeeze(0)\n",
        "\toutput = output.numpy()\n",
        "\t\n",
        "\ta = np.zeros_like(output)\n",
        "\ta = np.exp(output) - 1\n",
        "\n",
        "\tp = 2 * np.pi * np.random.random_sample(a.shape) - np.pi\n",
        "\t\n",
        "\n",
        "\tfor i in tqdm(range(500)):\n",
        "\t\tS = a * np.exp(1j*p)\n",
        "\t\tx = librosa.istft(S)\n",
        "\t\tp = np.angle(librosa.stft(x, N_FFT))\n",
        "\n",
        "\tOUTPUT_FILENAME = 'output.wav'\n",
        "\tsf.write(OUTPUT_FILENAME, x, style_sr)\n",
        "\n",
        "\tprint('DONE...')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMXjjPGts1LuYG0uGVCvThl"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}